FORMAT: 1A
<<<<<<< HEAD
# Cloudbreak

![SequenceIQ](https://raw.githubusercontent.com/sequenceiq/sequenceiq.github.io/master/img/logo.png)

*Cloudbreak is a powerful left surf that breaks over a coral reef, a mile off southwest the island of Tavarua, Fiji.*

*Cloudbreak is a cloud agnostic Hadoop as a Service API. Abstracts the provisioning and ease management and monitoring of on-demand clusters.*

SequenceIQ's Cloudbreak is a RESTful application development platform with the goal of helping developers to build solutions for deploying Hadoop YARN clusters in different environments. Once it is deployed in your favourite servlet container it exposes a REST API allowing to span up Hadoop clusters of arbitary sizes and cloud providers. Provisioning Hadoop has never been easier.
Cloudbreak is built on the foundation of cloud providers API (Amazon AWS, Microsoft Azure), Apache Ambari, Docker lightweight containers, Serf and dnsmasq. For further product documentation follow the link: http://sequenceiq.com/cloudbreak/


##Benefits

###Secure
Supports a token based and OAuth2 authentication model. The cluster is provisioned in a logically isolated network (Virtual Private Cloud) of your cloud favourite cloud provider. If the cluster is launched in a VPC network, the framework configure firewall settings that control the network access of your launched instances. For example a Hadoop Resource Manager can be accessed from the internet, whereas none of the other nodes are available. Cloudbreak does not store or manages your cloud credentials - it is the end user's responsibility to link Cloudbreak with her/his cloud account. We provide utilities to ease this process (IAM on Amazon, certificates on Azure).

###Elastic
Cloudbreak API can provision an arbitrary number of Hadoop nodes - the API does the hard work and span up the cluster, configure the networks and the selected Hadoop services without any interaction. POST once and use it anytime after.

###Scalable
As the workload changes, the API allows you to add or remove nodes on the fly. Cloudbreak does the hard work of reconfiguring the infrastructure, provision or decommission Hadoop nodes and let the cluster be continuously operational. Once provisioned, new nodes will take up the load and increase the cluster throughput.

###Declarative Hadoop clusters
Supports different Hadoop cluster blueprints. Hostgroups defined in blueprints can be associated to different VPC subnets and availability zones, thus you can span up a cluster for deploying highly available applications.

###Flexible
Allows the option to choose the favourite cloud provider and different pricing models. The API translated the calls towards different cloud vendors - uses one common API, no need to rewrite the code when changing between cloud providers.

# Group User authentication
*Note:* The **Cloudbreak API** no longer contains user authentication and user management endpoints as these became part of our OAuth2 based central identity management service.

All operations against the API must contain a valid access token obtained from our identity server.
The access token must travel in a standard **Authorization** header like `Authorization: Bearer some.valid.access.token`

Examples of getting an access token:
- with the **authorization_code** flow from a web application: [Uluwatu](https://github.com/sequenceiq/uluwatu/blob/master/server.js)
- with the **implicit** flow from a command line shell application: [Cloudbreak shell](https://github.com/sequenceiq/cloudbreak-shell/blob/master/src/main/java/com/sequenceiq/cloudbreak/shell/configuration/ShellConfiguration.java)

A token can only be obtained by a client that's registered at our identity server. Registering custom clients is currently not supported but planned in a later release.
If you'd like to create a custom client for our deployed Cloudbreak API and use our identity server, please contact us.

# Group Cloud authentication
Cloud Authentication related resources of the **Cloudbreak API**.
Adds an AWS IAM role ARN or Azure JKS to user's account.


## Add cloud credentials for a user [/user/credentials]
### Add credentials [POST]
Adds an AWS IAM role ARN with the user's account.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
               "name": "sqiq-0002",
               "cloudPlatform": "AWS",
               "description": "My aws credential",
               "publicKey": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCasJyap4swb4Hk4xOlnF3OmKVwzmv2e053yrtvcUPaxCeboSltOBReuTQxX+kYCgKCdtEwpIvEDXk16T6nCI4tSptAalFgpUWn+JOysCuLuWnwrk6mSKOzEiPYCrB54444mDY6rbBDSRuE/VUYQ/yi0imocARlOiFdPRlZGTN0XGE1V8LSo+m0oIzTwBKn58I4v5iB4ZUL/6adGXo7dgdBh/Fmm4uYbgrCZnL1kldjfksjdfkskdjlfEaKpMxSG76XWhuzFpHjLkRndz88ha0rB6davag6nZGdno5IepLAWg9oB4jTApHwhN2j1rWLN2y1c+pTxsF6LxBiN5rsYKR495VFmuOepLYz5I8Dn sequence-eu",
               "parameters": {
                   "roleArn": "arn:aws:iam::755047402263:role/seq-self-cf"
                }
            }

+ Response 201 (application/json)

        {
           "id":51
        }


## Add cloud credentials for the user [/user/credentials]
### Add credential [POST]
Adds an Azure JKS the user's account.

Use `openssl` to generate an X509 certificate with a 2048-bit RSA keypair. Please answer the few questions that the openssl prompts for (or you may leave them blank). The content in these fields is not used by the platform:

openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout myPrivateKey.key -out myCert.pem

The content of the myCert.pem file is the publicKey in the request

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "name": "sqiq-0001",
                "cloudPlatform": "AZURE",
                "description": "My azure credential",
                "publicKey": "-----BEGIN CERTIFICATE-----MIICsDCCAhmgAwIBAgIJAPtq+czPZYU/MA0GCSqGSIb3DQEBBQUAMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIEwpTb21lLVN0YXRlMSEwHw-----END CERTIFICATE-----",
                "parameters": {
                    "subscriptionId": "1234-5678-1234-5678",
                    "jksPassword": "pw123"
                }
            }

+ Response 201 (application/json)

        {
          "id":50
        }


## Retrieve cloud credentials for the user [/user/credentials]
### Retrieve credentials [GET]
Retrieves registered cloud credentials for a user

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        [
            {
                "id": 50,
                "description": "my sample description1",
                "parameters": {
                    "roleArn": "arn:aws:iam::755047402263:role/seq-self-cf",
                    "instanceProfileRoleArn": "arn:aws:iam::755047402263:instance-profile/readonly-role"
                },
                "cloudPlatform": "AWS",
                "name": "aws_credential"
            },
            {
                "id": 51,
                "description": "my sample description2",
                "parameters": {
                    "roleArn": "arn:aws:iam::755047402263:role/seq-self-cf"
                },
                "cloudPlatform": "AWS",
                "name": "lp-0002"
            }
        ]

## Retrieve a specific cloud credential for the user [/credentials/{id}]
### Retrieve credential [GET]

Retrieves the cloud credential (AWS or Azure) associated with the user account
+ Parameters
    + id (required String `id`) ... The identifier of the user cloud `credential` entry

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
            "id": 50,
            "description": "my sample description1",
            "parameters": {
                "roleArn": "arn:aws:iam::755047402263:role/seq-self-cf"
            },
            "cloudPlatform": "AWS",
            "name": "aws_credential"
        }


## Delete the specified cloud credentials from the user account [/credentials/{id}]
### Deletes the specified cloud credentials [DELETE]

+ Parameters
    + id (required String `id`) ... The identifier of cloud `credential`.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
        }


# Group Templates
Template  related resources of the **Cloudbreak API**.
AWS or Azure cloud templates allow configuration of VPC, subnet, internet gateway, route table, securityGroups, ACLs, instances.
Templates describe cloud infrastructures and are used for creating cloud stacks - such as running cloud infrastructures.
#### Our default AMIs on amazon:
  + eu-west-1: ami-7778af00
  + us-east-1: ami-d89955b0
  + us-west-2: ami-17b0c927
  + us-west-1: ami-314a4974
  + ap-southeast-1: ami-468bd214
  + ap-northeast-1: ami-0bcd9d0a
  + ap-southeast-2: ami-678bec5d
  + sa-east-1: ami-1b0ca206

#### Our default Image name on Azure:
  + ambari-docker-v1

#### Amazon instance types:
+ T2Micro
+ T2Small
+ T2Medium
+ M3Medium
+ M3Large
+ M3Xlarge
+ M32xlarge

#### Azure vm types:
+ EXTRA_SMALL
+ SMALL
+ MEDIUM
+ LARGE
+ EXTRA_LARGE

## Create cloud template [/user/templates]
### Create AWS template [POST]
Creates an AWS template (vpc, subnet, internetGateway, routeTable, securityGroups, ACLs, instances). The template internally is using an Amazon AWS Cloudformation template.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "cloudPlatform": "AWS",
                "name": "my-template-1",
                "description": "My aws template"
                "parameters": {
                    "sshLocation": "0.0.0.0/0"
                    "region": "eu-west-1",
                    "instanceType": "M3Xlarge",
                    "amiId": "ami-12345678"
                }
            }

+ Response 200 (application/json)

        {
            "id": "1"
        }


### Create Azure template [POST]
Creates an Azure cloud template. (vpc, subnet, instances)

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "cloudPlatform": "AZURE",
                "name": "my-azure-cluster",
                "description": "my azure template"
                "parameters": {
                    "location": "NORTH_EUROPE",
                    "imageName": "sequnceiq-ambari-docker-v1",
                    "password": "Password!@#$",
                    "vmType": "SMALL",
                }
            }

+ Response 200 (application/json)

        {
            "id": "2"
        }

## Retrieve templates for a user [/user/templates]
### List templates [GET]
Retrieves a list with the cloud templates belonging to the user

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
            }

+ Response 200 (application/json)

          [
              {
                  "cloudPlatform": "AWS",
                  "name": "my-template-1",
                  "description": "My azure template",
                  "parameters": {
                      "sshLocation": "0.0.0.0/0"
                      "region": "eu-west-1",
                      "keyName": "sequence-eu",
                      "instanceType": "m3.xlarge"
                      "amiId": "ami-12345678"
                    }
              },
              {
                  "cloudPlatform": "AZURE",
                  "name": "my-azure-cluster",
                  "description": "my azure template"
                  "parameters": {
                      "location": "NORTH_EUROPE",
                      "imageName": "sequnceiq-ambari-docker-v1",
                      "password": "Password!@#$",
                      "vmType": "SMALL",
                  }
              }
          ]


## Retrieve the given template for the user [/templates/{id}]
### Retrieve a particular AWS or Azure template by id [GET]
Retrieves the AWS or Azure template by submitting the template ID


+ Parameters
    + id (required String `id`) ... The identifier of the `template`.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
            "id":"stack-123",
            {
                "cloudPlatform": "AWS",
                "name": "my-template-1",
                "description": "My azure template",
                "parameters": {
                    "sshLocation": "0.0.0.0/0"
                    "region": "eu-west-1",
                    "keyName": "sequence-eu",
                    "instanceType": "m3.xlarge"
                    "amiId": "ami-12345678"
                }
            }
        }


## Delete the specified template from the database [/templates/{id}]
### Delete the specified template [DELETE]
Deletes the specified template from the database, unless there is a cloud instance created from this template.

+ Parameters
    + id (required String `id`) ... The identifier of the `template`.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
        }

# Group Blueprints
Hadoop blueprint  related resources of the **Cloudbreak API**.

Allows configurations of different blueprints to be used later to create Hadoop cluster instances.


## Adding Hadoop blueprints [/user/blueprints]
### Create blueprint [POST]

Creates a Hadoop blueprint. The blueprint specifies Hadoop services and other Hadoop specific configuration.
The cardinality specifies the desired number of nodes for the hostgroup. When the cluster is created this number can be overridden.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "name": "multi-node-hdfs-yarn",
                "description": "My multinode blueprint",
                "ambariBlueprint": {
                  "Blueprints": {
                    "blueprint_name": "multi-node-hdfs-yarn",
                    "stack_name": "HDP",
                    "stack_version": "2.0"
                  },
                  "hostGroups": [
                    {
                      "name": "master",
                      "components": [
                        {
                          "name": "NAMENODE"
                        },
                        {
                          "name": "SECONDARY_NAMENODE"
                        },
                        {
                          "name": "RESOURCEMANAGER"
                        },
                        {
                          "name": "HISTORYSERVER"
                        },
                        {
                          "name": "NAGIOS_SERVER"
                        },
                        {
                          "name": "ZOOKEEPER_SERVER"
                        }
                      ],
                      "cardinality": "1"
                    },
                    {
                      "name": "slaves",
                      "components": [
                        {
                          "name": "DATANODE"
                        },
                        {
                          "name": "HDFS_CLIENT"
                        },
                        {
                          "name": "NODEMANAGER"
                        },
                        {
                          "name": "YARN_CLIENT"
                        },
                        {
                          "name": "MAPREDUCE2_CLIENT"
                        },
                        {
                          "name": "ZOOKEEPER_CLIENT"
                        }
                      ],
                      "cardinality": "2"
                    }
                    ]
                  }
              }


+ Response 200 (application/json)

        {
        }


## Create Hadoop blueprints [/user/blueprints]
### Create a blueprint [POST]
Creates a Hadoop blueprint using the provided `url`

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "name": "multi-node-hdfs-yarn",
                "description": "My multinode blueprint",
                "url": "http://url.com/blueprint.json"
            }

+ Response 200 (application/json)

        {
        }


## Retrieve Hadoop blueprints [/user/blueprints]
### List blueprints for the user [GET]
Retrieve blueprints for the user

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
            }

+ Response 200 (application/json)

        {
            "id": "51"
            "name": "my-ambari-cluster-1",
            "description": "My multinode blueprint",
            "blueprintName": "multi-node-hdfs-yarn",
            "ambariBlueprint": {
              "host_groups" : [
                  {
                    "name" : "master",
                    "components" : [
                        {
                          "name" : "NAMENODE"
                        },
                        {
                          "name" : "SECONDARY_NAMENODE"
                        },
                        {
                          "name" : "RESOURCEMANAGER"
                        },
                        {
                          "name" : "HISTORYSERVER"
                        },
                        {
                          "name" : "NAGIOS_SERVER"
                        },
                        {
                          "name" : "ZOOKEEPER_SERVER"
                        }
                    ],
                    "cardinality" : "1"
                  },
                  {
                    "name" : "slaves",
                    "components" : [
                        {
                          "name" : "DATANODE"
                        },
                        {
                          "name" : "HDFS_CLIENT"
                        },
                        {
                          "name" : "NODEMANAGER"
                        },
                        {
                          "name" : "YARN_CLIENT"
                        },
                        {
                          "name" : "MAPREDUCE2_CLIENT"
                        },
                        {
                          "name" : "ZOOKEEPER_CLIENT"
                        }
                        ],
                        "cardinality" : "2"
                  }
                ],
                "Blueprints" : {
                  "blueprint_name" : "multi-node-hdfs-yarn",
                  "stack_name" : "HDP",
                  "stack_version" : "2.0"
                }
              }
        }


## Retrieve blueprints  [/blueprints/{id}]
### Retrieve a particular blueprint for the user [GET]

+ Parameters
    + id (required String `id`) ... The identifier of the `blueprint`

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
                "id": "51"
                "name": "my-ambari-cluster-1",
                "description": "My multinode blueprint",
                "blueprintName": "multi-node-hdfs-yarn",
                "ambariBlueprint": {
                "host_groups" : [
                      {
                        "name" : "master",
                        "components" : [
                            {
                              "name" : "NAMENODE"
                            },
                            {
                              "name" : "SECONDARY_NAMENODE"
                            },
                            {
                              "name" : "RESOURCEMANAGER"
                            },
                            {
                              "name" : "HISTORYSERVER"
                            },
                            {
                              "name" : "NAGIOS_SERVER"
                            },
                            {
                              "name" : "ZOOKEEPER_SERVER"
                            }
                        ],
                        "cardinality" : "1"
                      },
                      {
                        "name" : "slaves",
                        "components" : [
                            {
                              "name" : "DATANODE"
                            },
                            {
                              "name" : "HDFS_CLIENT"
                            },
                            {
                              "name" : "NODEMANAGER"
                            },
                            {
                              "name" : "YARN_CLIENT"
                            },
                            {
                              "name" : "MAPREDUCE2_CLIENT"
                            },
                            {
                              "name" : "ZOOKEEPER_CLIENT"
                            }
                            ],
                            "cardinality" : "2"
                      }
                    ],
                    "Blueprints" : {
                      "blueprint_name" : "multi-node-hdfs-yarn",
                      "stack_name" : "HDP",
                      "stack_version" : "2.0"
                    }
                  }
        }


## Delete blueprint [/blueprints/{id}]
### Deletes the specified blueprint [DELETE]
WARNING: Deletes the specified blueprint from the database.

+ Parameters
    + id (required String `id`) ... The identifier of the `blueprint`

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
        }


# Group Stacks
Stacks related resources of the **Cloudbreak API**.
Manages AWS or Azure clouds based on templates. Creates, launches, stops, deletes the specified number of instances in the selected template (infrastructure).


## Create cloud [/user/stacks]
### Create stack [POST]
Creates an AWS or Azure cloud from a template.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                "name": "my-cloud-1",
                "description": "my testing cloud",
                "clusterSize": 3,
                "templateId": "1"
            }

+ Response 200 (application/json)

        {
            "id": "1"
        }

## Retrieve stacks for the user [/user/stacks]
### List stacks [GET]
Retrieves the cloud stacks belonging to the user

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
            }

+ Response 200 (application/json)

        {
          [
            "metadata": [
              {
                "dockerSubnet": "172.17.10",
                "ambariServer": true,
                "instanceIndex": 0,
                "instanceId": "i-fab627b8",
                "publicIp": "54.77.43.59",
                "privateIp": "10.0.0.136"
              },
              {
                "dockerSubnet": "172.17.11",
                "ambariServer": false,
                "instanceIndex": 1,
                "instanceId": "i-1bb92859",
                "publicIp": "54.77.43.60",
                "privateIp": "10.0.0.135"
              },
              {
                "dockerSubnet": "172.17.12",
                "ambariServer": false,
                "instanceIndex": 2,
                "instanceId": "i-1ab92858",
                "publicIp": "54.77.43.61",
                "privateIp": "10.0.0.137"
              }
            ],
            "cluster": {
              "description": "",
              "blueprintId": 50,
              "cluster": {},
              "minutesUp": 8,
              "hoursUp": 0,
              "status": "CREATE_COMPLETED",
              "id": 2
            },
            "hash": "208d3dd389fad2221311792106cde53d",
            "ambariServerIp": "54.77.43.59",
            "nodeCount": 3,
            "name": "awstest",
            "templateId": 50,
            "credentialId": 50,
            "id": 50,
            "cloudPlatform": "AWS",
            "description": {
              --AWS DESCRIPTION--
            },
            "status": "CREATE_COMPLETED"
          ]
        }


## Retrieve a  stack [/stacks/{id}]
### Retrieve a particular stack [GET]
Retrieves a  (AWS or Azure)  stack definition.

+ Parameters
    + id (required String `id`) ... The identifier of the `stack`.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)

        {
          "metadata": [
            {
              "dockerSubnet": "172.17.10",
              "ambariServer": true,
              "instanceIndex": 0,
              "instanceId": "i-fab627b8",
              "publicIp": "54.77.43.59",
              "privateIp": "10.0.0.136"
            },
            {
              "dockerSubnet": "172.17.11",
              "ambariServer": false,
              "instanceIndex": 1,
              "instanceId": "i-1bb92859",
              "publicIp": "54.77.43.60",
              "privateIp": "10.0.0.135"
            },
            {
              "dockerSubnet": "172.17.12",
              "ambariServer": false,
              "instanceIndex": 2,
              "instanceId": "i-1ab92858",
              "publicIp": "54.77.43.61",
              "privateIp": "10.0.0.137"
            }
          ],
          "cluster": {
            "description": "",
            "blueprintId": 50,
            "cluster": {},
            "minutesUp": 8,
            "hoursUp": 0,
            "status": "CREATE_COMPLETED",
            "id": 2
          },
          "hash": "208d3dd389fad2221311792106cde53d",
          "ambariServerIp": "54.77.43.59",
          "nodeCount": 3,
          "name": "awstest",
          "templateId": 50,
          "credentialId": 50,
          "id": 50,
          "cloudPlatform": "AWS",
          "description": {
            --AWS DESCRIPTION--
          },
          "status": "CREATE_COMPLETED"
        }



## Delete cloud stacks [/stacks/{id}]
### Deletes the specified cloud stack [DELETE]
Deletes the specified stack from the (AWS or Azure) cloud

WARNING: All data will be lost - unless there was no storage configured. It is the user's responsibility to backup data or take snapshots using the cloud interface.

+ Parameters
    + id (required String `aws-cloud-id`) ... The identifier of the `stack`.

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

+ Response 200 (application/json)


          {

          }

## Retrieve a  stack [/stacks/metadata/{hash}]
### Retrieve a particular stack metadata [GET]
Retrieves a  (AWS or Azure)  stack metadata.

+ Parameters
    + hash (required String `hash`) ... The identifier of the `metadata`.

+ Response 200 (application/json)

  {
    [
      {
        "dockerSubnet": "172.17.12",
        "ambariServer": false,
        "instanceIndex": 2,
        "instanceId": "i-1ab92858",
        "publicIp": "54.77.43.61",
        "privateIp": "10.0.0.137"
      },
      {
        "dockerSubnet": "172.17.10",
        "ambariServer": true,
        "instanceIndex": 0,
        "instanceId": "i-fab627b8",
        "publicIp": "54.77.43.59",
        "privateIp": "10.0.0.136"
      },
      {
        "dockerSubnet": "172.17.11",
        "ambariServer": false,
        "instanceIndex": 1,
        "instanceId": "i-1bb92859",
        "publicIp": "54.77.43.60",
        "privateIp": "10.0.0.135"
      }
    ]
  }




# Group Clusters
Hadoop cluster related resources of the **Cloudbreak API**.


## Adding Hadoop clusters [/stacks/{stackId}/cluster]
### Create cluster [POST]
Creates a Hadoop cluster based on a blueprint.

+ Parameters
    + id (required String `id`) ... The identifier of the `stack`

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
                 "clusterName": "my-cluster",
                 "blueprintId": "1",
                 "description": "My multinode cluster"
            }

+ Response 200 (application/json)

        {
        }


## Retrieve Hadoop clusters [/stacks/{stackId}/cluster]
### Retrieve a particular cluster [GET]
Retrieves a particular cluster configuration for the user

+ Parameters
    + id (required String `id`) ... The identifier of the `stack`

+ Request

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
            }

+ Response 200 (application/json)

        {
          {
            "description": "",
            "blueprintId": 50,
            "cluster": {
              "configurations": [
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "capacity-scheduler",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=capacity-scheduler&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "core-site",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=core-site&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "global",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=global&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "hadoop-policy",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=hadoop-policy&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "hdfs-log4j",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=hdfs-log4j&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "hdfs-site",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=hdfs-site&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "mapred-queue-acls",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=mapred-queue-acls&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "mapred-site",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=mapred-site&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "yarn-log4j",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=yarn-log4j&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "yarn-site",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=yarn-site&tag=1"
                },
                {
                  "Config": {
                    "cluster_name": "awstest"
                  },
                  "type": "zookeeper-log4j",
                  "tag": "1",
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/configurations?type=zookeeper-log4j&tag=1"
                }
              ],
              "hosts": [
                {
                  "Hosts": {
                    "host_name": "amb0.mycorp.kom",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/hosts/amb0.mycorp.kom"
                },
                {
                  "Hosts": {
                    "host_name": "amb1.mycorp.kom",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/hosts/amb1.mycorp.kom"
                },
                {
                  "Hosts": {
                    "host_name": "amb2.mycorp.kom",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/hosts/amb2.mycorp.kom"
                }
              ],
              "workflows": [],
              "config_groups": [],
              "services": [
                {
                  "ServiceInfo": {
                    "service_name": "HDFS",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/services/HDFS"
                },
                {
                  "ServiceInfo": {
                    "service_name": "MAPREDUCE2",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/services/MAPREDUCE2"
                },
                {
                  "ServiceInfo": {
                    "service_name": "NAGIOS",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/services/NAGIOS"
                },
                {
                  "ServiceInfo": {
                    "service_name": "YARN",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/services/YARN"
                },
                {
                  "ServiceInfo": {
                    "service_name": "ZOOKEEPER",
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/services/ZOOKEEPER"
                }
              ],
              "requests": [
                {
                  "Requests": {
                    "id": 1,
                    "cluster_name": "awstest"
                  },
                  "href": "http://54.77.43.59:8080/api/v1/clusters/awstest/requests/1"
                }
              ],
              "Clusters": {
                "desired_configs": {
                  "zookeeper-log4j": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "yarn-site": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "yarn-log4j": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "capacity-scheduler": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "core-site": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "global": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "hadoop-policy": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "hdfs-log4j": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "hdfs-site": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "mapred-queue-acls": {
                    "tag": "1",
                    "user": "admin"
                  },
                  "mapred-site": {
                    "tag": "1",
                    "user": "admin"
                  }
                },
                "version": "HDP-2.1",
                "cluster_name": "awstest",
                "cluster_id": 2
              },
              "href": "http://54.77.43.59:8080/api/v1/clusters/awstest"
            },
            "minutesUp": 16,
            "hoursUp": 0,
            "status": "CREATE_COMPLETED",
            "id": 2
          }

        }

# Group Events

Events are used to track stack creation initiated by cloudbreak users.
Events are generated by the backend when resources requested by the user become available or unavailable


## Retrieve events [/user/events{?since}]
Retrieve events for the authenticated user.

+ Parameters
    + since (optional, string) ... Timestamp indicating the time the events will be returned from

+ Model (application/json)

    JSON representation of the event

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
               "eventTimestamp":"1409929066 ",
               "eventType":"STACK_STARTED",
               "eventMessage:"Stack started",
               "userName":"John Doe",
               "userId":14,
               "accountName":"Company gmbh."
               "accountId":5
               "eventDescription":"Stack Started",
               "cloud":"AWS",
               "region":"eu-west-1",
               "vmType":"xlarge",
               "blueprint":"lambda",
            }

### Retrieve events [GET]

+ Response 200

    [Retrieve events][]

# Group Usage

Usage resources provide insights into user activities.

## User usage [/user/usage{?since,cloud,zone,vmtype,hours,account,user,blueprint}]

+ Parameters
    + since (optional, string) ... timestamp indicating the day the usage information is to be retrieved from
    + cloud (optional, string) ... the cloud provider (eg.: AWS)
    + zone (optional, string) ... the region where the stack is running
    + vmtype (optional, string) ... the instance type
    + hours (optional, integer) ... the minimum amount of running hours
    + account (optional, long) ... account identifier
    + user (optional, long) ... user identifier
    + blueprint (optional, long) ... blueprint identifier

+ Model (application/json)

    JSON representation of the usage information

    + Headers

            x-auth-token: user:c45sdfdsfo234jgkhsdgf324

    + Body

            {
              "day":"2014/01/5",
              "cloud":"AWS",
              "region":"eu-west-1",
              "runningHours":"15",
              "account":"testing ltd",
              "blueprint":"lambda-architecture"
            }

### Retrieve user usage [GET]

Retrieve usage information for the authenticated user.

+ Response 200

     + Body

            { [
               {
                 "day":"2014/01/5",
                 "cloud":"AWS",
                 "region":"eu-west-1",
                 "runningHours":"15",
                 "account":"testing ltd",
                 "blueprint":"lambda-architecture"
                 "user":"John Doe"
               },
               {
                 "day":"2014/01/6",
                 "cloud":"AZURE",
                 "region":"eu-west-1",
                 "runningHours":"12",
                 "account":"testing ltd",
                 "blueprint":"multinode",
                 "user":"John Doe"
               }
               ...
               ]
            }

## Account usage [/account/usage{?since,cloud,zone,vmtype,hours,account,user,blueprint}]
### Retrieve filtered usage information for the account administrator [GET]

+ Response 200

     [User usage][]


## Deployer usage [/usage{?since,cloud,zone,vmtype,hours,account,user,blueprint}]
### Retrieve filtered usage for the deployer[GET]

Retrieve usage information for the deployer user.

+ Response 200

     [User usage][]
=======
# Periscope

![SequenceIQ](https://raw.githubusercontent.com/sequenceiq/sequenceiq.github.io/master/img/logo.png)

*Periscope is a powerful, fast, thick and top-to-bottom right-hander, eastward from Sumbawa's famous west-coast. Timing is critical, as needs a number of elements to align before it shows its true colors.*

*Periscope is a heuristic Hadoop scheduler you associate with a QoS profile. Built on YARN schedulers, cloud and VM resource management API's it allows you to associate SLA's to applications and customers.*
<<<<<<< HEAD
>>>>>>> f4bf1b1... PERI-2 apiary template added
=======

## Overview

The purpose of Periscope is to bring QoS to a multi-tenant Hadoop cluster, while allowing to apply SLA's to individual applications and customers.
At [SequenceIQ](http://sequenceiq.com) working with multi-tenant Hadoop clusters for quite a while we have always seen the same frustration and fight for resource between users.
The **FairScheduler** was partially solving this problem - bringing in fairness based on the notion of [Dominant Resource Fairness](http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf).
With the emergence of Hadoop 2 YARN and the **CapacityScheduler** we had the option to maximize throughput and the utilization of the cluster for a multi-tenant cluster in an operator-friendly manner.
The scheduler works around the concept of queues. These queues are typically setup by administrators to reflect the economics of the shared cluster.
While there is a pretty good abstraction and brings some level of SLA for `predictable` workloads, it often needs proper `design ahead`.
The queue hierarchy and resource allocation needs to be changed when new tenants and workloads are moved to the cluster.

Periscope was designed around the idea of `dynamic` clusters - without any need to preconfigure queues, cluster nodes or apply capacity planning ahead.

## How it works

Periscope monitors the application progress, the number of YARN containers/resources and their allocation on nodes, queue depths, and the number of nodes and their health.
Since we have switched to YARN a while ago (been among the first adopters) we have run an open source [monitoring project](https://github.com/sequenceiq/yarn-monitoring), based on R.
We have been collecting metrics from the YARN Timeline server, Hadoop Metrics2 and Ambari's Nagios/Ganglia - and profiling applications and correlating with these metrics.
One of the key findings we have found - and have applied to Periscope - was that while low level metrics are good to understand the cluster health - they might not necessarily help on making decisions when applying different SLA's on a multi-tenant cluster.
Focusing on higher level building blocks as queue depth, YARN containers, etc actually brings in the same quality of service, while not being lost in low level details.
We will follow up with examples and metrics on coming blog posts - make sure you follow us on [LinkedIn](https://www.linkedin.com/company/sequenceiq/), [Twitter](https://twitter.com/sequenceiq) or [Facebook](https://www.facebook).

_Example: Applying SLA based on `resource` load might not be the best solution - each application tasks generates different loads, and a CPU heavy reduce step might be followed by an I/O heavy mapper - making a decision based on a low `snapshot` might not be the right option.
Also note that a YARN cluster can run different applications - MR2, HBase, Spark, etc - and they all generate different load across different timeframes.
When YARN allocates containers it associates `resources` - it's actually more predictable to let YARN to deal with the resource allocation, and have Periscope orchestrate the process._

Periscope works with two types of Hadoop clusters: `static` and `dynamic`.

### Static clusters
From Periscope point of view we consider a cluster static when the cluster capacity can't be increased horizontally.
This means that the hardware resources are already given - and the throughput can't be increased by adding new nodes.
Periscope introspects the job submission process, monitors the applications and applies the following SLA's:

  1. Application ordering - can guaranty that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Attempts* to enforce time based SLA (execution time, finish by, finish between, recurring)
  4. *Attempts* to enforce guaranteed cluster capacity requests ( x % of the resources)
  5. Support for distributed (but not YARN ready) applications using Apache Slider

### Dynamic clusters
From Periscope point of view we consider a cluster dynamic when the cluster capacity can be increased horizontally.
This means that nodes can be added dynamically - thus the throughput can be increased or decreased based on the cluster load, and scheduled applications.
In order to do that Periscope instructs [Cloudbreak](http://sequenceiq.com/cloudbreak/) to add or remove nodes from the cluster based on the SLA's, load and thus continuously provide a high *quality of service* for the multi-tenand Hadoop cluster.
Just to refresh memories - [Cloudbreak](http://sequenceiq.com/products.html) is [SequenceIQ's](http://sequenceiq.com) open source, cloud agnostic Hadoop as a Service API.
Given the option of provisioning or decommissioning cluster nodes on the fly, Periscope allows you to use the following set of SLA's:

  1. Application ordering - can guaranty that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Enforce* time based SLA (execution time, finish by, finish between, recurring) by increasing cluster capacity and throughput
  4. Smart decommissioning - avoids HDFS storms, keeps `payed` nodes alive till the last minute
  5. *Enforce* guaranteed cluster capacity requests ( x % of the resources)
  6. *Private* cluster requests - supports provisioning of short lived private clusters with the possibility to merge
  7. Support for distributed (but not YARN ready) applications using Apache Slider
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 3b7285c... PERI-2 Transferring blueprint from apiary.io
=======
  
#Group Clusters 
=======

#Group Clusters
>>>>>>> 2a42905... PERI-2 update apiary
Clusters related resources of the **Periscope API**.

##Clusters [/clusters/{id}]
###Add a cluster [POST]
Add a cluster to be monitored by Periscope.

+ Parameters
    + id (required String `id`) ... The id of the cluster to be monitored.

+ Request (application/json)

        {
            "host": "172.24.0.2",
            "port": "8080",
            "user": "admin",
            "pass": "admin"
        }

+ Response 201 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }


##  Clusters [/clusters/{id}]
###Retrieved the monitored cluster information [GET]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request
        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##  Clusters [/clusters/{id}]
###Delete the monitored cluster from Periscope [DELETE]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request
        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##  Clusters [/clusters]
###Retrieved all the monitored cluster information [GET]

+ Request
        {

        }

+ Response 200 (application/json)

        [
          {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
          }
        ]

##Policy [/policy/{clusterId}/{policyName}]
###Create a scaling policy for a cluster [POST]
TBD - add the 3 different scenarios - success, partial and failure

+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster to attach the policy.
    + policyName (required String `policyName`) ... The name of the attached policy name to the cluster.

+ Request (application/json)

        {

            "jarUrl": "https://dl.dropboxusercontent.com/u/13919958/lostnodes.jar",
            "scaleUpRules":
            {
                "com.sequenceiq.periscope.policies.cloudbreak.rule.LostNodesRule":
                {
                    "limit": "4",
                    "lostNodes": "2"
                },
                "pendingApps":
                {
                    "limit": "4",
                    "pendingApps": "5"
                },
                "pendingContainers":
                {
                    "limit": "4",
                    "pendingContainers": "10"
                }
            },
            "scaleDownRules":
            {
                "resourcesAbove":
                {
                    "limit": "3",
                    "freeResourceRate": "0.4"
                }
            }
        }

+ Response 200 (application/json)

        {
            "scaleDownRules":
            {
                "resourcesAbove":
                {
                    "freeResourceRate": "0.4",
                    "limit": "3"
                }
            },
            "scaleUpRules":
            {
                "pendingApps":
                {
                    "pendingApps": "5",
                    "limit": "4"
                },
                "pendingContainers":
                {
                    "pendingContainers": "10",
                    "limit": "4"
                },
                "com.sequenceiq.periscope.policies.cloudbreak.rule.LostNodesRule":
                {
                    "lostNodes": "2",
                    "limit": "4"
                }
            },
            "jarUrl": "https://dl.dropboxusercontent.com/u/13919958/lostnodes.jar",
            "message": "Policy successfully added"
        }


##Policy [/policy/{clusterId}/{policyName}]
###Create a scaling policy for a cluster [GET]


+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster to attach the policy.
    + policyName (required String `policyName`) ... The name of the attached policy name to the cluster.

+ Request (application/json)

+ Response 200 (application/json)

        {
            "scaleDownRules":
            {
                "resourcesAbove":
                {
                    "freeResourceRate": "0.4",
                "limit": "3"
                }
            },
            "scaleUpRules":
            {
                "pendingApps":
                {
                    "pendingApps": "5",
                    "limit": "4"
                },
                "pendingContainers":
                {
                    "pendingContainers": "10",
                    "limit": "4"
                },
                "com.sequenceiq.periscope.policies.cloudbreak.rule.LostNodesRule":
                {
                    "lostNodes": "2",
                    "limit": "4"
                }
            },
            "jarUrl": "https://dl.dropboxusercontent.com/u/13919958/lostnodes.jar",
            "message": ""
        }

##Movements [/movement/{clusterId}}]
###Configure application movements withih a cluster [POST]

+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster.

+ Request (application/json)

        {
          "allowed": "false"
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##State [/state/{clusterId}]
###Set the state of a cluster [POST]

+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster.

+ Request (application/json)

        {
          "state": "SUSPENDED"
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##Applications [/applications/{clusterId}]
###List the running applications in a cluster [GET]

+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster.

+ Request (application/json)

        {
          "state": "SUSPENDED"
        }

+ Response 200 (application/json)

        [
            {
                "usedVCores": 1,
                "usedMemory": 512,
                "reservedContainers": 0,
                "usedContainers": 1,
                "appId": "application_1407836063840_0001",
                "user": "hdfs",
                "queue": "default",
                "state": "ACCEPTED",
                "url": "http://amb0.mycorp.kom:8088/proxy/application_1407836063840_0001/",
                "start": 1407847270776,
                "finish": 0,
                "progress": 0
              }
        ]
<<<<<<< HEAD
>>>>>>> e490783... PERI-2 apiary v1 added
=======

##Configuration [/configuration/{clusterId}]
###Reload the Hadoop configuration [POST]

+ Parameters
    + clusterId (required String `clusterIUD`) ... The id of the cluster.

+ Request (application/json)

        {
          "state": "SUSPENDED"
        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }
>>>>>>> 2a42905... PERI-2 update apiary
